# Proyecto de ConsolidaciÃ³n: Sistema de Scoring Crediticio
## Enhanced German Credit Data - ClasificaciÃ³n y Preprocesado

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto integrador combina los conocimientos de los mÃ³dulos:
- **Preprocesado, CreaciÃ³n y SelecciÃ³n de CaracterÃ­sticas**
- **Principales Algoritmos para ClasificaciÃ³n en Aprendizaje MÃ¡quina**

Los estudiantes trabajarÃ¡n en equipos de 3-5 personas para desarrollar un **sistema completo de evaluaciÃ³n de riesgo crediticio** utilizando el dataset Enhanced German Credit Data.

---

## ğŸ¯ Objetivos del Proyecto

1. **Aplicar tÃ©cnicas avanzadas de preprocesado de datos**
2. **Realizar feature engineering y selecciÃ³n de caracterÃ­sticas**
3. **Comparar mÃºltiples algoritmos de clasificaciÃ³n**
4. **Desarrollar un pipeline reproducible y libre de data leakage**
5. **Analizar e interpretar los resultados desde una perspectiva de negocio**

---

## ğŸ“Š Sobre el Dataset

### InformaciÃ³n General
- **Nombre**: Enhanced German Credit Data
- **Instancias**: 1,250 (aumento del 25% respecto al original)
- **Features**: 28 + 1 target
- **Objetivo**: Predecir si un cliente es "bueno" (1) o "malo" (2) para otorgar crÃ©dito

### Estructura de Variables

Explicada en el documento "german_credit_data_description.txt"
---

## ğŸ“ Entregables del Proyecto

### 1. **AnÃ¡lisis Exploratorio de Datos (EDA)** - 20%
- AnÃ¡lisis descriptivo completo de todas las variables
- Visualizaciones de distribuciones y relaciones
- IdentificaciÃ³n de problemas de calidad de datos
- AnÃ¡lisis de correlaciones
- DetecciÃ³n visual de outliers y valores faltantes

**Notebook**: `01_EDA.ipynb`

### 2. **Pipeline de Preprocesado** - 30%

Implementar y justificar:

#### A. Tratamiento de Valores Faltantes
- EliminaciÃ³n de filas (si procede)
- Estrategia de imputaciÃ³n 

#### B. DetecciÃ³n y Tratamiento de Outliers
- Identificar outliers usando al menos 2 mÃ©todos
- Aplicar tratamiento apropiado

#### C. Encoding de Variables CategÃ³ricas
- One-Hot Encoding para nominales
- Ordinal Encoding donde corresponda
- Target Encoding (opcional, si es apropiado)
- Manejo de categorÃ­as raras

#### D. TransformaciÃ³n de Variables
- NormalizaciÃ³n/EstandarizaciÃ³n segÃºn el algoritmo
- Transformaciones para normalidad (si es necesario)
- Justificar elecciones

#### E. Feature Engineering
- Crear al menos 3 features nuevas adicionales
- Justificar su utilidad potencial

#### F. SelecciÃ³n de Features
- Eliminar variables (si procede)
- Evaluar eliminaciÃ³n de variable/s correlacionada/s (si procede)
- Aplicar al menos 2 mÃ©todos de selecciÃ³n de variables:
  - MÃ©todos de filtro (correlaciÃ³n, chi-cuadrado, mutual information)
  - MÃ©todos wrapper (RFE)
  - Feature importance de modelos

**Notebook**: `02_Preprocesado.ipynb`

### 3. **Modelado y ComparaciÃ³n de Algoritmos** - 30%

Deben implementar y comparar **al menos 6 algoritmos**:

#### Algoritmos Obligatorios (mÃ­nimo 5):
1. RegresiÃ³n LogÃ­stica (baseline)
2. Decision Tree
3. Random Forest
4. XGBoost o LightGBM
5. SVM (con al menos 2 kernels diferentes)

#### Algoritmos Opcionales (elegir al menos 1):
6. K-Nearest Neighbors
7. Naive Bayes
8. Ensemble con Voting o Stacking
9. Otros (justificar)

#### Requisitos del Modelado:
- âœ… Usar validaciÃ³n cruzada estratificada (5-10 folds)
- âœ… Ajustar hiperparÃ¡metros (GridSearchCV o RandomizedSearchCV)
- âœ… Evitar data leakage (usar Pipelines de scikit-learn)
- âœ… Considerar el desbalanceo de clases:
  - SMOTE, ADASYN, undersampling
  - Class weights
  - Threshold tuning
- âœ… Considerar la matriz de costos (EXTRA: Opcional)
  - Costo de clasificar malo como bueno: 5
  - Costo de clasificar bueno como malo: 1

**Notebook**: `03_Modelado.ipynb`

### 4. **EvaluaciÃ³n y AnÃ¡lisis de Resultados** - 15%

#### MÃ©tricas de EvaluaciÃ³n:
- Accuracy (baseline)
- Precision, Recall, F1-Score (por clase)
- ROC-AUC
- Confusion Matrix
- **Costo total** (considerando la matriz de costos)
- Curvas de aprendizaje

#### AnÃ¡lisis Requerido:
- ComparaciÃ³n de algoritmos (tabla resumen)
- AnÃ¡lisis de feature importance
- InterpretaciÃ³n de errores (FP y FN)
- AnÃ¡lisis de costos de negocio
- Recomendaciones de umbrales de decisiÃ³n

**Notebook**: `04_Evaluacion.ipynb`

### 5. **PresentaciÃ³n Final y Reporte** - 5%

**Formato**: PDF o presentaciÃ³n (mÃ¡ximo 15 slides)

Contenido:
1. IntroducciÃ³n y contexto del problema
2. Resumen del preprocesado (decisiones clave)
3. Features mÃ¡s importantes identificadas
4. ComparaciÃ³n de algoritmos (tabla y grÃ¡ficos)
5. Modelo recomendado y justificaciÃ³n
6. AnÃ¡lisis de costos y ROI potencial
7. Limitaciones y trabajo futuro
8. Conclusiones

**Archivo**: `Reporte_Equipo_X.pdf`

---

## ğŸ”§ Estructura de Archivos propuesta

```
proyecto_credit_scoring/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ german_credit_data.txt             # Dataset original
â”‚   â””â”€â”€ german_credit_data_description.txt # DescripciÃ³n
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Preprocesado.ipynb
â”‚   â”œâ”€â”€ 03_Modelado.ipynb
â”‚   â””â”€â”€ 04_Evaluacion.ipynb
â”‚
â”œâ”€â”€ src/                                 # (Opcional) Scripts reutilizables
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â””â”€â”€ modeling.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                         # GrÃ¡ficos generados
â”‚   â”œâ”€â”€ models/                          # Modelos entrenados (.pkl)
â”‚   â””â”€â”€ results/                         # Tablas de resultados
â”‚
â”œâ”€â”€ README.md                            # Este archivo
â”œâ”€â”€ requirements.txt                     # Dependencias
â””â”€â”€ Reporte_Equipo_X.pdf                # Reporte final
```

---

## EvaluaciÃ³n

| Criterio | Peso | DescripciÃ³n |
|----------|------|-------------|
| **EDA** | 20% | Completitud, visualizaciones, insights |
| **Preprocesado** | 30% | JustificaciÃ³n de decisiones, implementaciÃ³n correcta, ausencia de data leakage |
| **Modelado** | 30% | Diversidad de algoritmos, optimizaciÃ³n, validaciÃ³n correcta |
| **EvaluaciÃ³n** | 15% | MÃ©tricas apropiadas, interpretaciÃ³n, anÃ¡lisis de negocio |
| **PresentaciÃ³n** | 5% | Claridad, estructura, conclusiones |

### Criterios EspecÃ­ficos de EvaluaciÃ³n:

**Excelente (9-10)**
- Todas las tÃ©cnicas implementadas correctamente
- Justificaciones sÃ³lidas basadas en anÃ¡lisis
- Pipeline reproducible sin data leakage
- AnÃ¡lisis profundo de resultados
- Insights valiosos de negocio

**Bueno (7-8)**
- MayorÃ­a de tÃ©cnicas implementadas
- Justificaciones razonables
- Pipeline funcional con mÃ­nimos errores
- AnÃ¡lisis completo de mÃ©tricas
- InterpretaciÃ³n correcta

**Suficiente (5-6)**
- TÃ©cnicas bÃ¡sicas implementadas
- Algunas justificaciones presentes
- Pipeline con algunos errores
- MÃ©tricas bÃ¡sicas reportadas
- InterpretaciÃ³n superficial

**Insuficiente (<5)**
- TÃ©cnicas incompletas o incorrectas
- Falta de justificaciÃ³n
- Data leakage presente
- MÃ©tricas inadecuadas
- InterpretaciÃ³n incorrecta

---

## ğŸ’¡ Consejos y Buenas PrÃ¡cticas

### âœ… DO
- Documentar todas las decisiones de preprocesado
- Usar sklearn Pipelines para evitar data leakage
- Validar con datos de test independientes
- Considerar el contexto de negocio al interpretar
- Guardar modelos y transformadores entrenados
- Usar control de versiones (Git)
- Realizar anÃ¡lisis de sensibilidad de hiperparÃ¡metros

### âŒ DON'T
- Aplicar fit() en datos de test
- Eliminar datos sin justificaciÃ³n
- Ignorar el desbalanceo de clases
- Usar solo accuracy como mÃ©trica
- Copiar cÃ³digo sin entender
- Olvidar la reproducibilidad (semillas aleatorias)
- Ignorar la matriz de costos del problema

---

## ğŸ“– Referencias Ãštiles

### DocumentaciÃ³n
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Feature-engine](https://feature-engine.readthedocs.io/)

### Tutoriales Recomendados
- [Handling Missing Data](https://scikit-learn.org/stable/modules/impute.html)
- [Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)
- [Pipeline and ColumnTransformer](https://scikit-learn.org/stable/modules/compose.html)
- [Imbalanced-learn](https://imbalanced-learn.org/stable/)

### Papers Relevantes
- SMOTE: Synthetic Minority Over-sampling Technique
- Random Forest: Breiman (2001)
- XGBoost: Chen & Guestrin (2016)

---

## â“ Preguntas Frecuentes

**P: Â¿Podemos usar otras librerÃ­as ademÃ¡s de scikit-learn?**
R: SÃ­, pueden usar pandas, numpy, matplotlib, seaborn, feature-engine, imbalanced-learn, xgboost, lightgbm, catboost, etc. Deben incluir todas las dependencias en requirements.txt.

**P: Â¿CuÃ¡ntos features debemos crear?**
R: MÃ­nimo 3 features nuevas ademÃ¡s de las ya incluidas. La calidad es mÃ¡s importante que la cantidad - justificar por quÃ© cada feature podrÃ­a ser Ãºtil.

**P: Â¿Debemos eliminar las variables de ruido identificadas?**
R: SÃ­, es parte del ejercicio de selecciÃ³n de features. Deben demostrar que identifican y eliminan features irrelevantes.

**P: Â¿CÃ³mo manejamos variables correlacionadas?**
R: Analicen la correlaciÃ³n, evalÃºen el impacto en los modelos con y sin ella, y tomen una decisiÃ³n justificada.

**P: Â¿Es obligatorio usar la matriz de costos?**
R: No, es opcional, aunque recomendable. Pueden considerar los costos diferentes de FP y FN en su anÃ¡lisis final y recomendaciones.

**P: Â¿Podemos usar deep learning?**
R: El enfoque debe estar en los algoritmos vistos en clase (regresiÃ³n logÃ­stica, Ã¡rboles, random forest, xgboost, svm, knn, naive bayes). No debe emplearse Deep learning ni ninguna otra teÂ´cnica no vista en clase.

---

## ğŸ“§ Contacto y Soporte

Para dudas sobre el proyecto:
- Consultar el syllabus de los mÃ³dulos
- Revisar la descripciÃ³n detallada del dataset
- Contactar al instructor durante las sesiones

---

## ğŸ“ CrÃ©ditos

**Dataset Original**: German Credit Data, UCI Machine Learning Repository  
**Dataset Ampliado**: VersiÃ³n educativa con features adicionales para prÃ¡ctica de preprocesado y ClasificaciÃ³n
**Curso**: MÃ¡ster en Inteligencia Artificial - MBIT School
**MÃ³dulos**: Preprocesado y Algoritmos de ClasificaciÃ³n
**Profesor**: Juan JosÃ© GarcÃ©s Iniesta; jjgarcesiniesta@gmail.com 
---

**Â¡Buena suerte con el proyecto! ğŸš€**

---
# EOF (End Of File)